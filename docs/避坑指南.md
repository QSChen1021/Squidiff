# Squidiff 项目复现避坑指南

> 本指南总结了项目复现过程中可能遇到的各种"坑"及解决方案，帮助您快速搭建环境并成功运行模型。

---

## 目录

- [环境配置陷阱](#环境配置陷阱)
- [数据格式陷阱](#数据格式陷阱)
- [GPU/CUDA 相关陷阱](#gpucuda-相关陷阱)
- [模型训练陷阱](#模型训练陷阱)
- [模型推理陷阱](#模型推理陷阱)
- [版本兼容陷阱](#版本兼容陷阱)
- [复现检查清单](#复现检查清单)

---

## 环境配置陷阱

### ⚠️ 陷阱 1: 依赖缺失导致运行时错误

**问题描述**: `pyproject.toml` 中 `dependencies` 为空，但代码实际依赖多个包。

```toml
# pyproject.toml 第 8-9 行
dependencies = [  # 空的！
]
```

**实际需要的依赖**:
- `torch` (PyTorch 深度学习框架)
- `scanpy` (单细胞数据分析)
- `numpy` (数值计算)
- `rdkit` (化学信息学，用于 SMILES 处理)
- `scipy` (科学计算)
- `scikit-learn` (机器学习工具)
- `matplotlib` (绘图)
- `h5py` (HDF5 文件格式)

**解决方案**:

```bash
# 方案 1: 使用 uv 安装（推荐）
uv pip install torch scanpy numpy rdkit scipy scikit-learn matplotlib h5py seurat-disk

# 方案 2: 使用 pip
pip install torch scanpy numpy rdkit scipy scikit-learn matplotlib h5py seurat-disk

# 方案 3: 从 requirements.txt 安装（需要先创建）
pip install -r requirements.txt
```

**建议**: 创建 `requirements.txt` 文件固定依赖版本。

---

### ⚠️ 陷阱 2: PyTorch CUDA 版本不匹配

**问题描述**: 安装的 PyTorch 版本与系统 CUDA 版本不匹配，导致 `cuda.is_available()` 返回 `False`。

**检测方法**:
```python
import torch
print(f"CUDA 可用: {torch.cuda.is_available()}")
print(f"CUDA 版本: {torch.version.cuda}")
print(f"PyTorch 版本: {torch.__version__}")
```

**解决方案**:

```bash
# 检查系统 CUDA 版本
nvcc --version

# 根据 CUDA 版本安装对应的 PyTorch
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPU 版本（无 GPU 时）
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

---

### ⚠️ 陷阱 3: 虚拟环境未激活

**问题描述**: 在项目目录中存在 `.venv`，但未激活导致使用全局 Python 环境。

**解决方案**:

```bash
# Linux/macOS
source .venv/bin/activate

# Windows
.venv\Scripts\activate

# 验证
which python  # Linux/macOS
where python  # Windows
```

---

### ⚠️ 陷阱 4: RDKit 安装失败

**问题描述**: RDKit 的 pip 安装在某些环境下可能失败。

**解决方案**:

```bash
# 方案 1: 使用 conda（最可靠）
conda install -c conda-forge rdkit

# 方案 2: 使用预编译的 wheel
pip install rdkit

# 如果失败，尝试从源码编译（不推荐，耗时）
```

---

## 数据格式陷阱

### ⚠️ 陷阱 5: 表达矩阵格式错误

**问题描述**: `adata.X` 的格式不符合代码预期。

**代码位置**: `scrna_datasets.py:38-47`

```python
# 代码支持的两种格式
if isinstance(adata.X, np.ndarray):
    self.features = torch.tensor(adata.X, dtype=torch.float32)
else:
    self.features = torch.tensor(adata.X.toarray(), dtype=torch.float32)
```

**问题**:
1. **密集矩阵 vs 稀疏矩阵**: 代码假设 `toarray()` 方法存在（稀疏矩阵）
2. **数据类型**: 必须可转换为 `float32`
3. **维度**: 必须是 (n_cells, n_genes)

**解决方案**:

```python
import scanpy as sc
from scipy.sparse import issparse

# 读取数据
adata = sc.read_h5ad("data.h5ad")

# 检查格式
print(f"矩阵类型: {type(adata.X)}")
print(f"是否稀疏: {issparse(adata.X)}")
print(f"数据类型: {adata.X.dtype}")

# 如果需要转换
if issparse(adata.X):
    # 转为密集矩阵（小数据集）
    adata.X = adata.X.toarray()
else:
    # 转为稀疏矩阵（大数据集）
    from scipy import sparse
    adata.X = sparse.csr_matrix(adata.X)

# 确保 float32 类型
import numpy as np
if adata.X.dtype != np.float32:
    adata.X = adata.X.astype(np.float32)
```

---

### ⚠️ 陷阱 6: 基因数不匹配

**问题描述**: `gene_size` 参数与实际数据基因数不一致。

**错误信息**:
```
RuntimeError: mat1 and mat2 shapes cannot be multiplied
```

**代码位置**: `train_squidiff.py:121`, `sample_squidiff.py:87-88`

**解决方案**:

```python
# 检查实际基因数
import scanpy as sc
adata = sc.read_h5ad("data.h5ad")
print(f"实际基因数: {adata.n_vars}")

# 训练时使用正确的 gene_size
python train_squidiff.py \
  --gene_size {adata.n_vars} \
  --output_dim {adata.n_vars} \
  ...
```

---

### ⚠️ 陷阱 7: 缺少必需的 metadata 列

**问题描述**: 代码假设 `adata.obs` 中存在 `Group` 列，但实际数据中没有。

**代码位置**: `scrna_datasets.py:49, 52, 56`

```python
self.drug_type_list = adata.obs['SMILES'].to_list()
self.dose_list = adata.obs['dose'].to_list()
self.encoded_obs_tensor = adata.obs['Group'].copy().values
```

**错误信息**:
```
KeyError: 'Group'
```

**解决方案**:

```python
import scanpy as sc
import pandas as pd

adata = sc.read_h5ad("data.h5ad")

# 检查现有列
print(adata.obs.columns.tolist())

# 添加 Group 列
if 'Group' not in adata.obs.columns:
    # 方法 1: 使用细胞类型
    adata.obs['Group'] = adata.obs['cell_type']

    # 方法 2: 使用聚类结果
    # adata.obs['Group'] = adata.obs['seurat_clusters']

    # 方法 3: 创建组合标签
    # adata.obs['Group'] = adata.obs['condition'] + '_' + adata.obs['cell_type']

# 验证
print(f"Group 唯一值: {adata.obs['Group'].unique()}")

# 保存
adata.write_h5ad("data_with_group.h5ad")
```

---

### ⚠️ 陷阱 8: SMILES 格式错误（使用药物结构时）

**问题描述**: SMILES 字符串无效，导致 RDKit 处理失败。

**代码位置**: `scrna_datasets.py:18-32`

**解决方案**:

```python
from rdkit import Chem

def validate_smiles(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        return mol is not None
    except:
        return False

# 检查所有 SMILES
adata = sc.read_h5ad("data.h5ad")

if 'SMILES' in adata.obs.columns:
    adata.obs['valid_smiles'] = adata.obs['SMILES'].apply(validate_smiles)

    invalid_count = (~adata.obs['valid_smiles']).sum()
    print(f"无效 SMILES 数量: {invalid_count}")

    if invalid_count > 0:
        print("无效的 SMILES:")
        print(adata[~adata.obs['valid_smiles']].obs[['SMILES', 'drug_name']])

        # 移除无效数据
        adata = adata[adata.obs['valid_smiles']].copy()
        adata.write_h5ad("data_cleaned.h5ad")
```

---

## GPU/CUDA 相关陷阱

### ⚠️ 陷阱 9: 硬编码 CUDA 设备

**问题描述**: 代码中存在硬编码的 `.to('cuda')`，在没有 GPU 的环境下会报错。

**代码位置**: `sample_squidiff.py:50, 122, 161`

```python
# 硬编码示例
timestep = torch.full((x.shape[0],), i, device='cuda').long()  # 第 50 行
```

**解决方案**: 使用项目提供的 `dist_util.dev()` 函数：

```python
# 错误方式
x = x.to('cuda')

# 正确方式
from Squidiff import dist_util
x = x.to(dist_util.dev())

# 或者动态检测
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
x = x.to(device)
```

**建议**: 项目应修复 `sample_squidiff.py` 中的硬编码问题。

---

### ⚠️ 陷阱 10: GPU 内存不足

**问题描述**: 数据集过大导致 GPU 内存溢出。

**错误信息**:
```
RuntimeError: CUDA out of memory
```

**解决方案**:

```bash
# 方案 1: 减小 batch_size
python train_squidiff.py --batch_size 32 ...

# 方案 2: 减小 gene_size（选择高变基因）
python train_squidiff.py --gene_size 500 ...

# 方案 3: 使用梯度累积
python train_squidiff.py --microbatch 16 --batch_size 64 ...

# 方案 4: 使用混合精度训练
python train_squidiff.py --use_fp16 True ...
```

---

### ⚠️ 陷阱 11: 多 GPU 分布式训练配置错误

**问题描述**: 代码包含分布式训练逻辑，但环境变量未正确设置。

**代码位置**: `dist_util.py:20-47`

**解决方案**:

```python
# 单 GPU 训练（默认）
python train_squidiff.py ...

# 多 GPU 训练（需要配置）
# 设置环境变量
export CUDA_VISIBLE_DEVICES=0,1  # Linux
set CUDA_VISIBLE_DEVICES=0,1     # Windows

# 或使用 torchrun
torchrun --nproc_per_node=2 train_squidiff.py ...
```

---

## 模型训练陷阱

### ⚠️ 陷阱 12: 随机种子未设置

**问题描述**: 代码中没有设置随机种子，导致每次训练结果不可复现。

**代码位置**: `resample.py:54` 使用 `np.random.choice` 但无种子设置

**解决方案**:

```python
import random
import numpy as np
import torch

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

# 在训练脚本开始时调用
set_seed(42)
```

**建议**: 在 `train_squidiff.py` 中添加种子设置参数。

---

### ⚠️ 陷阱 13: 学习率衰减步数设置不当

**问题描述**: `lr_anneal_steps` 与实际训练步数不匹配。

**代码位置**: `train_squidiff.py:189-190`, `train_util.py:279-285`

```python
while (
    not self.lr_anneal_steps
    or self.step + self.resume_step < self.lr_anneal_steps
):
```

**问题**: 如果设置过小，训练会过早停止。

**解决方案**:

```bash
# 根据 epoch 数和 dataset 大小计算
# 公式: lr_anneal_steps = num_epochs * (num_samples / batch_size)

# 示例: 100 epochs, 10000 samples, batch_size 64
# lr_anneal_steps = 100 * (10000 / 64) ≈ 15625

python train_squidiff.py --lr_anneal_steps 15625 ...
```

---

### ⚠️ 陷阱 14: 日志和检查点路径不存在

**问题描述**: `--logger_path` 指定的目录不存在，导致保存失败。

**代码位置**: `train_squidiff.py:51`, `train_util.py:296-298`

**解决方案**:

```python
import os

logger_path = "path/to/logger"

# 自动创建目录
os.makedirs(logger_path, exist_ok=True)

# 然后训练
python train_squidiff.py --logger_path {logger_path} ...
```

---

### ⚠️ 陷阱 15: 对照组数据路径缺失

**问题描述**: 使用 `--use_drug_structure True` 但未提供 `--control_data_path`。

**代码位置**: `train_squidiff.py:63`

```python
control_data_dir=args['control_data_path'],
```

**解决方案**:

```bash
# 必须同时提供两个路径
python train_squidiff.py \
  --data_path datasets/treated.h5ad \
  --control_data_path datasets/control.h5ad \
  --use_drug_structure True \
  ...
```

---

## 模型推理陷阱

### ⚠️ 陷阱 16: 模型加载路径错误

**问题描述**: 模型检查点文件不存在或路径错误。

**解决方案**:

```python
import os

# 检查文件是否存在
model_path = "path/to/model.pt"
if not os.path.exists(model_path):
    # 列出可用的模型文件
    model_dir = os.path.dirname(model_path)
    if os.path.exists(model_dir):
        print("可用的模型文件:")
        for f in os.listdir(model_dir):
            if f.endswith('.pt'):
                print(f"  - {os.path.join(model_dir, f)}")
    else:
        print(f"目录不存在: {model_dir}")
else:
    print(f"模型文件存在: {model_path}")
```

---

### ⚠️ 陷阱 17: 推理时参数与训练时不一致

**问题描述**: 推理时使用的 `gene_size`、`output_dim` 等参数与训练时不同。

**解决方案**:

```python
# 记录训练参数
train_params = {
    'gene_size': 500,
    'output_dim': 500,
    'use_drug_structure': True,
    'drug_dimension': 1024,
    'num_layers': 3,
    'use_encoder': True,
}

# 保存参数到模型目录
import json
with open('model_params.json', 'w') as f:
    json.dump(train_params, f)

# 推理时加载
with open('model_params.json', 'r') as f:
    params = json.load(f)

sampler = sample_squidiff.sampler(
    model_path='model.pt',
    gene_size=params['gene_size'],
    output_dim=params['output_dim'],
    use_drug_structure=params['use_drug_structure']
)
```

---

### ⚠️ 陷阱 18: 输入数据维度与模型不匹配

**问题描述**: 推理时输入数据的维度与模型期望不符。

**解决方案**:

```python
import scanpy as sc
import torch

# 加载数据
test_adata = sc.read_h5ad('test_data.h5ad')

# 检查维度
print(f"数据基因数: {test_adata.n_vars}")

# 如果不匹配，进行基因对齐
# 假设训练时使用的基因列表
train_genes = [...]  # 从训练数据获取

# 筛选或填充基因
if test_adata.n_vars != len(train_genes):
    # 方法 1: 取交集
    common_genes = [g for g in train_genes if g in test_adata.var_names]
    test_adata = test_adata[:, common_genes]

    # 方法 2: 填充缺失基因为 0
    # ...（更复杂，需要基因对齐）
```

---

## 版本兼容陷阱

### ⚠️ 陷阱 19: Python 版本不兼容

**问题描述**: 项目要求 Python >= 3.8，但某些依赖包需要更高版本。

**解决方案**:

```bash
# 检查 Python 版本
python --version

# 推荐版本
# Python 3.8 - 3.10（最稳定）
# Python 3.11+（可能有兼容性问题）

# 使用 pyenv 或 conda 管理版本
pyenv install 3.9.18
pyenv local 3.9.18
```

---

### ⚠️ 陷阱 20: Scanpy 版本更新导致 API 变化

**问题描述**: Scanpy 不同版本的 API 可能有差异。

**解决方案**:

```bash
# 固定 Scanpy 版本
pip install scanpy==1.9.6

# 或在 requirements.txt 中指定
echo "scanpy==1.9.6" >> requirements.txt
```

---

### ⚠️ 陷阱 21: h5ad 文件版本不兼容

**问题描述**: 不同版本的 h5py/AnnData 可能导致文件读取失败。

**解决方案**:

```python
import scanpy as sc
import h5py

# 检查版本
print(f"Scanpy 版本: {sc.__version__}")
print(f"h5py 版本: {h5py.__version__}")

# 如果读取失败，尝试重新保存
try:
    adata = sc.read_h5ad("data.h5ad")
except Exception as e:
    print(f"读取失败: {e}")
    # 尝试使用旧版本读取，然后重新保存
    # pip install 'h5py<3.0'
```

---

## 复现检查清单

### 环境检查

- [ ] Python 版本 >= 3.8
- [ ] PyTorch 已安装且 CUDA 版本匹配
- [ ] `torch.cuda.is_available()` 返回 `True`（如使用 GPU）
- [ ] 所有依赖包已安装（torch, scanpy, numpy, rdkit, scipy, h5py）
- [ ] 虚拟环境已激活

### 数据检查

- [ ] h5ad 文件可读取
- [ ] `adata.X` 格式正确（ndarray 或 sparse）
- [ ] `adata.obs['Group']` 列存在
- [ ] 如使用药物结构：`adata.obs['SMILES']` 和 `adata.obs['dose']` 存在
- [ ] SMILES 格式验证通过
- [ ] 基因数与 `--gene_size` 参数一致

### 训练前检查

- [ ] `--logger_path` 目录已创建或可创建
- [ ] `--data_path` 文件存在
- [ ] 如使用药物结构：`--control_data_path` 文件存在
- [ ] `--gene_size` 与数据基因数一致
- [ ] `--output_dim` 与 `gene_size` 一致（通常）
- [ ] `--batch_size` 根据数据大小和 GPU 内存合理设置
- [ ] `--lr_anneal_steps` 根据训练轮数合理设置

### 推理前检查

- [ ] 模型文件存在
- [ ] 模型参数（gene_size, output_dim 等）与训练时一致
- [ ] 测试数据基因数与训练数据一致
- [ ] 测试数据包含必需的 metadata 列

### 代码质量检查

- [ ] 通过 ruff 检查：`python -m ruff check .`
- [ ] 代码风格一致

---

## 常见错误速查表

| 错误信息 | 可能原因 | 解决方案 |
|----------|----------|----------|
| `KeyError: 'Group'` | 缺少 Group 列 | 添加 `adata.obs['Group']` |
| `RuntimeError: mat1 and mat2 shapes cannot be multiplied` | gene_size 不匹配 | 检查并修正 `--gene_size` |
| `CUDA out of memory` | GPU 内存不足 | 减小 batch_size 或 gene_size |
| `KeyError: 'SMILES'` | 缺少 SMILES 列 | 添加或设置 `use_drug_structure=False` |
| `FileNotFoundError` | 路径不存在 | 检查并创建目录 |
| `ModuleNotFoundError: No module named 'xxx'` | 依赖未安装 | 安装缺失的包 |
| `ValueError: Unknown dataset format` | h5ad 文件损坏 | 重新转换数据 |

---

## 推荐的最佳实践

### 1. 使用固定版本的依赖

创建 `requirements.txt`:

```txt
torch==2.0.1
scanpy==1.9.6
numpy==1.24.3
scipy==1.10.1
scikit-learn==1.2.2
matplotlib==3.7.1
h5py==3.8.0
rdkit==2023.3.1
seurat-disk==0.0.12
```

### 2. 创建配置文件

创建 `config.yaml`:

```yaml
data:
  train_path: "datasets/train.h5ad"
  control_path: "datasets/control.h5ad"
  gene_size: 500

model:
  num_layers: 3
  hidden_size: 2048
  use_encoder: true
  use_drug_structure: true

training:
  batch_size: 64
  lr: 1.0e-4
  lr_anneal_steps: 100000
  save_interval: 10000
  logger_path: "logs/experiment1"
```

### 3. 添加数据验证脚本

创建 `validate_data.py`:

```python
import scanpy as sc
from rdkit import Chem
import numpy as np

def validate_data(data_path, use_drug_structure=False):
    adata = sc.read_h5ad(data_path)

    print(f"细胞数: {adata.n_obs}")
    print(f"基因数: {adata.n_vars}")
    print(f"矩阵类型: {type(adata.X)}")

    assert 'Group' in adata.obs.columns, "缺少 Group 列"

    if use_drug_structure:
        assert 'SMILES' in adata.obs.columns, "缺少 SMILES 列"
        assert 'dose' in adata.obs.columns, "缺少 dose 列"

        valid_smiles = adata.obs['SMILES'].apply(
            lambda x: Chem.MolFromSmiles(x) is not None
        )
        assert valid_smiles.all(), "存在无效的 SMILES"

    print("✓ 数据验证通过")
    return True

if __name__ == "__main__":
    import sys
    validate_data(sys.argv[1], use_drug_structure=len(sys.argv) > 2)
```

### 4. 记录实验参数

每次训练后保存参数和结果：

```python
import json
import shutil

# 保存训练参数
with open(f'{logger_path}/train_params.json', 'w') as f:
    json.dump(vars(args), f, indent=2)

# 保存代码版本
shutil.copytree('Squidiff', f'{logger_path}/code')
```

---

## 获取帮助

如果遇到本指南未覆盖的问题：

1. **查看 GitHub Issues**: https://github.com/siyuh/Squidiff/issues
2. **查看复现仓库**: https://github.com/siyuh/Squidiff_reproducibility
3. **联系作者**: siyuhe@stanford.edu

---

*文档最后更新：2025年*
*基于 Squidiff v1.0.8*
